{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6JugdXMe0Z7x"
      },
      "outputs": [],
      "source": [
        "# Creating the postcode centroid file\n",
        "# I'm importing argparse so I can use it to sync devices from cloud APIs, ingest the postcode centroids, and fill any missing historicla data if required.\n",
        "# Importing logging to make debugging easier as it'll tell me where the issue is, for example which API link may be causing the issue.\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "# Importing requests so that my postcode centroid URL can be fetched and used.\n",
        "# SQLAlchemy helps connect me to TimeScaleDB for the dashboard and automatically reconnects to Render.\n",
        "import requests\n",
        "from sqlalchemy import create_engine, text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "postcode_centroid_URL = \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/ONSPD_LATEST_UK/FeatureServer/1\"\n",
        "\n",
        "inner_london_lad_codes = [\n",
        "    \"E09000001\",\"E09000007\",\"E09000012\",\"E09000013\",\"E09000019\",\"E09000020\",\n",
        "    \"E09000022\",\"E09000023\",\"E09000025\",\"E09000028\",\"E09000030\",\"E09000032\",\"E09000033\"\n",
        "]\n",
        "\n",
        "def normalisation(postcode):\n",
        "    p = postcode.strip().upper().replace(\" \", \"\")\n",
        "    if len(p) > 3:\n",
        "        p = p[:-3] + \" \" + p[-3:]\n",
        "    return p\n",
        "\n",
        "def build_where_inner_london():\n",
        "    # LAD25CD IN ('E09000001', 'E09000007', ...)\n",
        "    codes = \",\".join([f\"'{c}'\" for c in inner_london_lad_codes])\n",
        "    return f\"LAD25CD IN ({codes})\"\n",
        "\n",
        "# Since I know the max record count per page is 2000 and features of the URL from the directory\n",
        "# Creating a function so that I can later call it to create pages of london centroid postcodes with the chosen features.\n",
        "def query_page(postcode_centroid_URL,where,page_size,session,timeout = 120, retries = 4):\n",
        "  parameters = {\n",
        "      \"where\": where,\n",
        "      \"outFields\": \"PCDS,LONG,LAT,OBJECTID,LAD25CD\",\n",
        "      \"f\": \"json\",\n",
        "      \"resultRecordCount\": page_size,\n",
        "      \"orderByFields\":\"OBJECTID\",\n",
        "      \"returnGeometry\":\"false\"\n",
        "      }\n",
        "  # Adding the /query to the URL so that I can extract all the features required.\n",
        "  query_response = postcode_centroid_URL+ \"/query\"\n",
        "\n",
        "\n",
        "  # Creating a for loop in the event that the URL does not work the first time it will retry 4 times before saying it really won't work\n",
        "  for attempt in range(retries):\n",
        "    try:\n",
        "      # If the call works then it will get all the features stated in parameters and put them in a list for me\n",
        "      r = session.get(query_response, params = parameters, timeout = timeout)\n",
        "      r.raise_for_status()\n",
        "      data = r.json()\n",
        "\n",
        "      # If there is an error then it'll tell me the error so I can debug/fix it\n",
        "      if \"error\" in data:\n",
        "        raise RuntimeError(data[\"error\"])\n",
        "\n",
        "      # This part gathers all the features: \"PCDS,LONG,LAT,OBJECTID,LAD25CD\" and will put all its attributes in a list\n",
        "      features = data.get(\"features\", [])\n",
        "      return [f.get(\"attributes\",{}) for f in features]\n",
        "\n",
        "    # This part is so that instead of immediately crashing, it will wait 1.5s intervals and try again\n",
        "    except Exception:\n",
        "      #small wait, then retries\n",
        "      time.sleep(1.5 * (attempt + 1))\n",
        "\n",
        "  # If it still fails\n",
        "  raise RuntimeError(\"Failed to fetch data\")\n",
        "\n",
        "# I am now calling all the inner London postcode centroids into pages through paginiation\n",
        "\n",
        "session = requests.Session()\n",
        "last_objectid = 0\n",
        "page_size = 2000\n",
        "all_london_rows = []\n",
        "\n",
        "while True:\n",
        "  where = build_where_inner_london() + f\" AND OBJECTID > {last_objectid}\"\n",
        "  page = query_page(\n",
        "      postcode_centroid_URL,\n",
        "      where = where,\n",
        "      page_size = page_size,\n",
        "      session = session\n",
        "  )\n",
        "  print(f\"Last OBJECTID: {last_objectid}, got {len(page)} records\")\n",
        "\n",
        "  if not page or len(page) == 0:\n",
        "    print(\"Breaking - empty page\")\n",
        "    break\n",
        "\n",
        "  # Making sure the loop continues until there are no more postcodes\n",
        "  all_london_rows.extend(page)\n",
        "\n",
        "  new_last = page[-1].get(\"OBJECTID\")\n",
        "  if new_last is None or new_last <= last_objectid:\n",
        "      print(\"Breaking - OBJECTID did not advance (pagination issue)\")\n",
        "      break\n",
        "  last_objectid = new_last\n",
        "\n",
        "  # Stop if we got less than a full page (means we're at the end)\n",
        "  if len(page) < page_size:\n",
        "    print(f\"Breaking - partial page ({len(page)} records)\")\n",
        "    break\n",
        "\n",
        "print(\"All London postcode centroids have been fetched. The total number of rows are\", len(all_london_rows))\n",
        "\n",
        "# Doing a mini EDA to ensure there are no duplicate postcodes\n",
        "cleaned_list = []\n",
        "added_pcds = set()\n",
        "\n",
        "for row in all_london_rows:\n",
        "  pcds = row.get(\"PCDS\")\n",
        "  lat = row.get(\"LAT\")\n",
        "  long = row.get(\"LONG\")\n",
        "  # This removes any of the objectid completely if it doesn't contain all the features req\n",
        "  if pcds is None or lat is None or long is None:\n",
        "    continue\n",
        "  # Calling the normalisation function created earlier\n",
        "  pcds_norm = normalisation(str(pcds))\n",
        "  if pcds_norm in added_pcds:\n",
        "    continue\n",
        "\n",
        "  added_pcds.add(pcds_norm)\n",
        "  cleaned_list.append({\"Postcodes\": pcds_norm, \"Latitude\": float(lat), \"Longitude\": float(long)})\n",
        "\n",
        "\n",
        "print(\"These are the unique postcodes of London\", len(cleaned_list))\n",
        "\n",
        "# Saving it in a csv\n",
        "with open(\"innerLondon_postcode_centroids.csv\", \"w\", encoding = \"utf-8\") as f:\n",
        "  f.write(\"Postcodes,Latitude,Longitude\\n\")\n",
        "  for row in sorted(cleaned_list, key = lambda x: x[\"Postcodes\"]):\n",
        "    f.write(f\"{row['Postcodes']}, {row['Latitude']}, {row['Longitude']}\\n\")\n",
        "\n",
        "print(\"The CSV file has been saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFisPSK86yD5",
        "outputId": "e4df543a-17f3-4f99-cec6-d7c208aa2f1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last OBJECTID: 0, got 2000 records\n",
            "Last OBJECTID: 748597, got 2000 records\n",
            "Last OBJECTID: 753363, got 2000 records\n",
            "Last OBJECTID: 755371, got 2000 records\n",
            "Last OBJECTID: 757371, got 2000 records\n",
            "Last OBJECTID: 759452, got 2000 records\n",
            "Last OBJECTID: 764952, got 2000 records\n",
            "Last OBJECTID: 766973, got 2000 records\n",
            "Last OBJECTID: 770583, got 2000 records\n",
            "Last OBJECTID: 772591, got 2000 records\n",
            "Last OBJECTID: 774647, got 2000 records\n",
            "Last OBJECTID: 776662, got 2000 records\n",
            "Last OBJECTID: 778662, got 2000 records\n",
            "Last OBJECTID: 780662, got 2000 records\n",
            "Last OBJECTID: 782662, got 2000 records\n",
            "Last OBJECTID: 784662, got 2000 records\n",
            "Last OBJECTID: 786662, got 2000 records\n",
            "Last OBJECTID: 788662, got 2000 records\n",
            "Last OBJECTID: 1503492, got 2000 records\n",
            "Last OBJECTID: 1505492, got 2000 records\n",
            "Last OBJECTID: 1514097, got 2000 records\n",
            "Last OBJECTID: 1518751, got 2000 records\n",
            "Last OBJECTID: 1527941, got 2000 records\n",
            "Last OBJECTID: 1703467, got 2000 records\n",
            "Last OBJECTID: 1705467, got 2000 records\n",
            "Last OBJECTID: 1712450, got 2000 records\n",
            "Last OBJECTID: 1717099, got 2000 records\n",
            "Last OBJECTID: 1720667, got 2000 records\n",
            "Last OBJECTID: 1723029, got 2000 records\n",
            "Last OBJECTID: 2090456, got 2000 records\n",
            "Last OBJECTID: 2092456, got 2000 records\n",
            "Last OBJECTID: 2095653, got 2000 records\n",
            "Last OBJECTID: 2098054, got 2000 records\n",
            "Last OBJECTID: 2100064, got 2000 records\n",
            "Last OBJECTID: 2102089, got 2000 records\n",
            "Last OBJECTID: 2104118, got 2000 records\n",
            "Last OBJECTID: 2110888, got 2000 records\n",
            "Last OBJECTID: 2112920, got 2000 records\n",
            "Last OBJECTID: 2116222, got 2000 records\n",
            "Last OBJECTID: 2119752, got 2000 records\n",
            "Last OBJECTID: 2121752, got 2000 records\n",
            "Last OBJECTID: 2317241, got 2000 records\n",
            "Last OBJECTID: 2319242, got 2000 records\n",
            "Last OBJECTID: 2322613, got 2000 records\n",
            "Last OBJECTID: 2324704, got 2000 records\n",
            "Last OBJECTID: 2327298, got 2000 records\n",
            "Last OBJECTID: 2329373, got 2000 records\n",
            "Last OBJECTID: 2334000, got 2000 records\n",
            "Last OBJECTID: 2336000, got 2000 records\n",
            "Last OBJECTID: 2338000, got 2000 records\n",
            "Last OBJECTID: 2340000, got 2000 records\n",
            "Last OBJECTID: 2342978, got 2000 records\n",
            "Last OBJECTID: 2345025, got 2000 records\n",
            "Last OBJECTID: 2347032, got 2000 records\n",
            "Last OBJECTID: 2349049, got 2000 records\n",
            "Last OBJECTID: 2351071, got 2000 records\n",
            "Last OBJECTID: 2353090, got 2000 records\n",
            "Last OBJECTID: 2521601, got 2000 records\n",
            "Last OBJECTID: 2524077, got 2000 records\n",
            "Last OBJECTID: 2527221, got 2000 records\n",
            "Last OBJECTID: 2529221, got 2000 records\n",
            "Last OBJECTID: 2531320, got 2000 records\n",
            "Last OBJECTID: 2533321, got 2000 records\n",
            "Last OBJECTID: 2535321, got 2000 records\n",
            "Last OBJECTID: 2537321, got 2000 records\n",
            "Last OBJECTID: 2539321, got 2000 records\n",
            "Last OBJECTID: 2541321, got 2000 records\n",
            "Last OBJECTID: 2543321, got 2000 records\n",
            "Last OBJECTID: 2545321, got 2000 records\n",
            "Last OBJECTID: 2547321, got 2000 records\n",
            "Last OBJECTID: 2549352, got 2000 records\n",
            "Last OBJECTID: 2558494, got 2000 records\n",
            "Last OBJECTID: 2560494, got 2000 records\n",
            "Last OBJECTID: 2588742, got 2000 records\n",
            "Last OBJECTID: 2590742, got 2000 records\n",
            "Last OBJECTID: 2592742, got 2000 records\n",
            "Last OBJECTID: 2594742, got 120 records\n",
            "Breaking - partial page (120 records)\n",
            "All London postcode centroids have been fetched. The total number of rows are 152120\n",
            "These are the unique postcodes of London 152120\n",
            "The CSV file has been saved\n"
          ]
        }
      ]
    }
  ]
}